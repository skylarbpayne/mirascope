{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# o1 Style Thinking\n",
    "\n",
    "In this recipe, we will show how to achieve Chain-of-Thought Reasoning.\n",
    "This makes LLMs to breakdown the task in multiple steps and generate a coherent output allowing to solve complex tasks in logical steps.\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "<p class=\"admonition-title\">Mirascope Concepts Used</p>\n",
    "<ul>\n",
    "<li><a href=\"../../../learn/prompts/\">Prompts</a></li>\n",
    "<li><a href=\"../../../learn/calls/\">Calls</a></li>\n",
    "<li><a href=\"../../../learn/response_models/\">Response Models</a></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "<p class=\"admonition-title\">Background</p>\n",
    "<p>\n",
    "    Large Language Models (LLMs) are known to generate text that is coherent and fluent. However, they often struggle with tasks that require multi-step reasoning or logical thinking. In this recipe, we will show how to use Mirascope to guide the LLM to break down the task into multiple steps and generate a coherent output.\n",
    "\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To set up our environment, first let's install all of the packages we will use:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"mirascope[groq]\" \n",
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Set the appropriate API key for the provider you're using\n",
    "# Here we are using GROQ_API_KEY\n",
    "\n",
    "export GROQ_API=\"Your API Key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Chain-of-Thought Reasoning\n",
    "\n",
    "We will begin by showing how a typical LLM performs on a task that requires multi-step reasoning. In this example, we will ask the model to generate a count the number of `s`s in the word `Mississssippi` (Yes it has 7`s`'s). We will use the `llama-3.1-8b-instant` for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(User): how many s's in the word mississssippi\n",
      "(Assistant): There are 5 s's in the word 'mississippi'.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from mirascope.core import groq\n",
    "\n",
    "history: list[dict[str, str]] = []\n",
    "\n",
    "\n",
    "@groq.call(\"llama-3.1-8b-instant\")\n",
    "def generate_answer(question: str) -> str:\n",
    "    return f\"Generate an answer to this question: {question}\"\n",
    "\n",
    "\n",
    "def run() -> None:\n",
    "    question: str = \"how many s's in the word mississssippi\"\n",
    "    response: str = generate_answer(question)\n",
    "    print(f\"(User): {question}\")\n",
    "    print(f\"(Assistant): {response}\")\n",
    "    history.append({\"role\": \"user\", \"content\": question})\n",
    "    history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the zero-shot method is used to generate the output. The model is not provided with any additional information or context to help it generate the output. The model is only given the input prompt and asked to generate the output.\n",
    "\n",
    "This is not so effective when there is a logcial task to be performed.\n",
    "\n",
    "Now let's see how the model performs on this task when it can reason using Chain-of-Thought Reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Chain of Thought Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(User): How many s's are in the word 'mississssippi'?\n",
      "Step 1: Identifying the Task and Clarifying the Question:\n",
      "The task requires me to determine the number of 's' surnames in the word 'mississssippi'. However, the terminology 'surnames' might be misleading here since we are talking about the word 'mississssippi', a word that consists of multiple letters and not names.\n",
      "\n",
      "Assuming the correct interpretation of the task is to count the number of 's' occurrences in the word 'mississssippi', it seems we are dealing with a relatively straightforward task. The first step would be:\n",
      "\n",
      "1.1: Breaking down the word 'mississssippi' into individual letters to visually inspect and manipulate the letters. By doing this, we can then observe the number of times the letter 's' repeats.\n",
      "\n",
      "Upon visual inspection of the letters in 'mississssippi', the word contains:\n",
      "\n",
      "m-i-s-s-i-s-s-s-s-s-i-p-p-i\n",
      "\n",
      "1.2: Observing the consistency of my visual inspection of the letters by reading them together. Analyzing each character, the s in the given is counted when its correct alphabetical order. While in the alphabetical order A to Z, every character remains the same, when specifically choosing one letter, sometimes using them just for individual purposes it might be understood in a personal way of showing with alphabetic order.\n",
      "**Thinking time: 1.40 seconds**\n",
      "\n",
      "Step 2: Identifying the Consistent Pattern of Consecutive 's's:\n",
      "Upon breaking down the word 'mississssippi' into individual letters and visually inspecting them, I notice that the sequence of consecutive 's's follows a consistent pattern. To confirm this observation, I will count the consecutive occurrences of 's' in the word, separating the non-'s' characters from the consecutive sequence of 's's.\n",
      "\n",
      "From the original visual inspection of the letters:\n",
      "m-i-s-s-i-s-s-s-s-s-i-p-p-i\n",
      "\n",
      "Breaking down the consecutive 's' sequence:\n",
      "- 's' appears as the 3rd letter\n",
      "- it appears 6 more times in a row consecutively\n",
      "\n",
      "The non-'s' characters in the word 'mississssippi' might be used to temporarily separate the sequences, looking at the initial sequence this occurs at: 'i-s-s-i'. Now using each 's' for counting, we are examining specific sequences, determining when another 's' is encountered. \n",
      "\n",
      "By focusing only on the sequence of consecutive 's's in the word, I can see that it occurs 9 times in the given word.\n",
      "\n",
      "However, to avoid undercounting or overcounting, I will re-examine this task using an alternative approach.\n",
      "**Thinking time: 1.43 seconds**\n",
      "\n",
      "Step 3: Re-examining the Task Using a Counting Approach:\n",
      "In an attempt to validate the initial observation of consecutive 's' sequences and their count, I will employ a direct counting method to determine the number of 's' occurrences in the word 'mississssippi'. This approach may offer an alternative perspective, confirming or refuting the initial count based on the visually inspected sequence.\n",
      "\n",
      "Upon choosing the word \"mississssippi\" and placing all individual  letters in one line we get:\n",
      "m - i - s - s - i - s - s - s - s - s - i - p - p - i\n",
      "\n",
      "I will start at the very beginning and manually count the number of times the letter 's' appears. Keeping track of the count can help eliminate any potential biases or overlooks, also maintaining constant awareness with the objective goal. This straightforward counting process can provide reassurance that the observations from the initial and alternative inspection methods are accurate.\n",
      "\n",
      "1. Counting the first 's' at the 3rd position,\n",
      "2. The next consecutive 's' appears afterward, at the 4th position,\n",
      "3. Counting the consecutive 's' sequences, note the 's' at 4 is indeed followed by an additional 's' located at position 5.\n",
      "4. The next 's' appears after that one, located at 6, but of course that is obviously a following 's'.\n",
      "5. And so does the following 's's appear until it finishes counting.\n",
      "This manual counting might potentially show results different from the previously established ideas based upon where multiple 's's would appear at many places.\n",
      "\n",
      "At this point, we have counted 9 's's in the manual approach. However, I will further validate the results using an elimination-comparison method to ensure the reliability and consistency of our initial analysis.\n",
      "**Thinking time: 1.64 seconds**\n",
      "\n",
      "Step 4: Validation Through an Elimination-Comparison Method:\n",
      "To further validate the results and ensure the reliability and consistency of our initial analysis, I will employ an elimination-comparison method. This involves cross-checking the counts obtained from the visually inspected sequences and the direct counting method.\n",
      "\n",
      "The manual count from Step 3 manually counting 's's matches the count from the initial observation of consecutive 's' sequences in the word. To confirm this, I will compare each manual count with the expected number of 's's in each sequence.\n",
      "\n",
      "1. The sequence starts with the character 'm', which is not an 's'.\n",
      "2. In the first sequence (m, i, s, s, i, s, ...), we observe 3 's's. Since 'm' and 'i' appear before the first 's', they do not contribute to the count for the consecutive 's' sequence. Therefore, this count aligns with the direct counting method.\n",
      "3. For each subsequent sequence, we can confirm the number of 's's in the direct counting method matches the observed count of consecutive 's's.\n",
      "\n",
      "Upon analyzing each sequence and matching the counts, I confirm that the manual count of 9 's's matches the initial observation and the counts from the other approaches. Using this method, we have exhaustively validated our initial count and ensured that it is consistent across different inspection techniques.\n",
      "**Thinking time: 1.45 seconds**\n",
      "\n",
      "Final Answer:\n",
      "6\n",
      "**Thinking time: 1.01 seconds**\n",
      "\n",
      "**Total thinking time: 6.92 seconds**\n"
     ]
    }
   ],
   "source": [
    "from mirascope.core import groq\n",
    "\n",
    "\n",
    "history: list[dict] = []\n",
    "\n",
    "MODEL = \"llama-3.1-8b-instant\"\n",
    "\n",
    "\n",
    "@groq.call(MODEL)\n",
    "def cot_step(prompt: str, step_number: int, previous_steps: str) -> str:\n",
    "    return f\"\"\"\n",
    "    You are an expert AI assistant that explains your reasoning step by step. For this step, provide a title that describes what you're doing, along with the content. Decide if you need another step or if you're ready to give the final answer.\n",
    "\n",
    "    USE AS MANY REASONING STEPS AS POSSIBLE. AT LEAST 3. BE AWARE OF YOUR LIMITATIONS AS AN LLM AND WHAT YOU CAN AND CANNOT DO. IN YOUR REASONING, INCLUDE EXPLORATION OF ALTERNATIVE ANSWERS. CONSIDER YOU MAY BE WRONG, AND IF YOU ARE WRONG IN YOUR REASONING, WHERE IT WOULD BE. FULLY TEST ALL OTHER POSSIBILITIES. YOU CAN BE WRONG. WHEN YOU SAY YOU ARE RE-EXAMINING, ACTUALLY RE-EXAMINE, AND USE ANOTHER APPROACH TO DO SO. DO NOT JUST SAY YOU ARE RE-EXAMINING. USE AT LEAST 3 METHODS TO DERIVE THE ANSWER. USE BEST PRACTICES.\n",
    "\n",
    "    IMPORTANT: DO NOT USE CODE BLOCKS OR PROGRAMMING EXAMPLES IN YOUR REASONING. EXPLAIN YOUR PROCESS IN PLAIN LANGUAGE.\n",
    "\n",
    "    This is step number {step_number}.\n",
    "\n",
    "    Question: {prompt}\n",
    "\n",
    "    Previous steps:\n",
    "    {previous_steps}\n",
    "\n",
    "    Respond in the following format:\n",
    "    Step {step_number}: [Title]\n",
    "    [Content]\n",
    "    Next action: [continue/final_answer]\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "@groq.call(MODEL)\n",
    "def final_answer(prompt: str, reasoning: str) -> str:\n",
    "    return f\"\"\"\n",
    "    Based on the following chain of reasoning, provide a final answer to the question. Only provide the text response without any titles or preambles. Retain any formatting as instructed by the original prompt, such as exact formatting for free response or multiple choice.\n",
    "\n",
    "    Question: {prompt}\n",
    "\n",
    "    Reasoning:\n",
    "    {reasoning}\n",
    "\n",
    "    Final Answer:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def generate_cot_response(\n",
    "    user_query: str,\n",
    ") -> tuple[list[tuple[str, str, float]], float]:\n",
    "    steps: list[tuple[str, str, float]] = []\n",
    "    total_thinking_time: float = 0.0\n",
    "    step_count: int = 1\n",
    "    reasoning: str = \"\"\n",
    "    previous_steps: str = \"\"\n",
    "\n",
    "    while True:\n",
    "        start_time: datetime = datetime.now()\n",
    "        step_result: str = cot_step(user_query, step_count, previous_steps).content\n",
    "        end_time: datetime = datetime.now()\n",
    "        thinking_time: float = (end_time - start_time).total_seconds()\n",
    "\n",
    "        lines = step_result.strip().split(\"\\n\")\n",
    "        title = lines[0].split(\": \", 1)[1]\n",
    "        content = \"\\n\".join(lines[1:-1])\n",
    "        next_action = lines[-1].split(\": \", 1)[1]\n",
    "\n",
    "        steps.append((f\"Step {step_count}: {title}\", content, thinking_time))\n",
    "        total_thinking_time += thinking_time\n",
    "\n",
    "        reasoning += f\"\\n{step_result}\\n\"\n",
    "        previous_steps += f\"\\n{step_result}\\n\"\n",
    "\n",
    "        if next_action.lower() == \"final_answer\" or step_count >= 5:\n",
    "            break\n",
    "\n",
    "        step_count += 1\n",
    "\n",
    "    # Generate final answer\n",
    "    start_time = datetime.now()\n",
    "    final_result: str = final_answer(user_query, reasoning).content\n",
    "    end_time = datetime.now()\n",
    "    thinking_time = (end_time - start_time).total_seconds()\n",
    "    total_thinking_time += thinking_time\n",
    "\n",
    "    steps.append((\"Final Answer\", final_result, thinking_time))\n",
    "\n",
    "    return steps, total_thinking_time\n",
    "\n",
    "\n",
    "def display_cot_response(\n",
    "    steps: list[tuple[str, str, float]], total_thinking_time: float\n",
    ") -> None:\n",
    "    for title, content, thinking_time in steps:\n",
    "        print(f\"{title}:\")\n",
    "        print(content.strip())\n",
    "        print(f\"**Thinking time: {thinking_time:.2f} seconds**\\n\")\n",
    "\n",
    "    print(f\"**Total thinking time: {total_thinking_time:.2f} seconds**\")\n",
    "\n",
    "\n",
    "def run() -> None:\n",
    "    question: str = \"How many s's are in the word 'mississssippi'?\"\n",
    "    print(\"(User):\", question)\n",
    "    # Generate COT response\n",
    "    steps, total_thinking_time = generate_cot_response(question)\n",
    "    display_cot_response(steps, total_thinking_time)\n",
    "\n",
    "    # Add the interaction to the history\n",
    "    history.append({\"role\": \"user\", \"content\": question})\n",
    "    history.append(\n",
    "        {\"role\": \"assistant\", \"content\": steps[-1][1]}\n",
    "    )  # Add only the final answer to the history\n",
    "\n",
    "\n",
    "# Run the function\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated in the COT Reasoning example, we can guide the model to break down the task into multiple steps and generate a coherent output. This allows the model to solve complex tasks in logical steps.\n",
    "However, this requires multiple calls to the model, which may be expensive in terms of cost and time.\n",
    "Also model may not always identify the correct steps to solve the task, hence is not deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Chain of Thought Reasoning is a powerful technique that allows LLMs to solve complex tasks in logical steps. However, it requires multiple calls to the model and may not always identify the correct steps to solve the task. This technique can be useful when the task requires multi-step reasoning or logical thinking.\n",
    "\n",
    "Care should be taken to ensure that the model is guided correctly and that the output is coherent and accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
